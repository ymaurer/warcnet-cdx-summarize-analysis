---
title: "cdx-summarize_analysis"
output: html_document
date: "2023-05-16"
editor_options: 
  chunk_output_type: console
---
New version of the script started 16.05.2023 to include the analysis and visualizations for the chapter (and to clean up previous versions).
Work in progress!

NB: Change chunk input to inline in order to include them in the report if knitted

# Load libraries
```{r}
# install.packages(c("pacman","tidyverse","here","fs","ggplot2","reshape2","scales"))

pacman::p_load(tidyverse,here,fs,ggplot2,reshape2,scales)
# here() makes it easy to access data and files in the project directory thereby avoiding 
# using pull paths
# fs is for file system stuff, e.g., dir_ls
# scales is used to show percentage on the y axis
```

# Set working directory
```{r}
setwd("/Users/au148767/R_Projects/warcnet-cdx-summarize-analysis/")
```

### TO DO: Explain how we get from the summary files to the files with stat a, b, c and the overlap analyses. Are all the stats done with the warcnetstats.py script?

# Comments on the data
Most of the data used are what we have called statistics a, b and c (IS IT CREATED USING THE SCRIPT warcnetstats.py?). The statistics are the number of distinct domains, distinct top-level domains and distinct second-level domains, and for each we include the total number (called "overall") and the number per year. There are six different web archives involved: four national archives and two international archives. For the national archives, we have the three statistics both for everything in the archive ("all") and for just the nation's ccTLD (dk, fr, hu, and lu, respectively), resulting in a total of 12 files per archive. For the international archives, we have each of the four ccTLDs mentioned, resulting in 24 files per archive. This results in a total of 96 files.
However, not all the statistics are relevant for each archive. The stats from the international archives only include one tld, hence it does not make sense to look at statistics b (tld) for IA and CC. In the same way, statistics b for the ccTLD version of the national archives are irrelevant. This removes 16 + 8 = 24 files.
We also have to think about duplicates, since some of the files include numbers that are the same or part of the same. Statistics c (lvl2-per-tld) from the ccTLD version of the national archive stats are already included in the file with the "overall" data from the same archive, so we need to remove these files to not get duplicates, when we do analysis based on stat c (here, Analysis 3: Each ccTLD across all archives). This removes 8 files.
For the overlap analysis, we have 4 files (HOW ARE THESE CREATED?), leaving a total of 68 files.
If you need to see a list of the files in the data folder, use list.files("data/").

# Create read files function
A function for loading a set of cvs files into a dataframe while including (part of) the filename in a column (name "collection").
```{r}
read_data_files <- function(folder, glob_expression, col_names) {
  dir_ls(here(folder), glob = glob_expression) %>% 
    map_dfr(
      \(filename) {
        print(filename);
        read_csv(filename, col_names = col_names)  %>%
          add_column(
            collection = paste(str_split(basename(filename),"-",simplify = T)[1:2], collapse = "-")
          )
      }
    )
}
```

# Colors & linetypes
"Internet Archive" : "#000000" : "dashed"
"Common Crawl" : "#3a3a3a" : "dotdash"
"Bibliothèque nationale de France" : "#838383" : "twodash"
"Luxembourg Web Archive" : "#aeaeae" : "solid"
"Netarkivet" : "#c9c9c9" : "dotted"
"Hungary Web Archive" : "#e5e5e5" : "longdash"

# 1. Total number of distinct domains from all countries and archives
Based on stata-distinct-domains-overall
```{r}
# read files with distinct domains overall (only one number)
distinct_domains_overall <- read_data_files("data", "*distinct-domains-overall.csv", c("n")) %>% 
  separate(collection, c("archive", "country"), remove=FALSE) # create columns with archive and country based on file name

# write to csv (optional)
# write_csv(distinct_domains_overall, "results/distinct_domains_overall.csv")
```

# 2. Number of distinct domains in all archives across years shown as facets
Based on stata-distinct-domains-per-year
###TO DO: find a way to sort the facets so they appear in the correct order 
```{r}
# read files and remove years that are errors
clean_domains_per_year <- read_data_files("data","*domains-per-year.csv", c("year", "count")) %>%  
  filter(year > 1992)  %>%
  filter(year < 2022) %>% 
  separate(collection, c("archive", "country"), remove=FALSE)

# to see how many years are represented for each country in each archive 
# clean_domains_per_year %>% count(archive, country)

# collections as facets, full version
clean_domains_per_year %>% 
  ggplot(aes(x=year, y=count/1000000)) +
  geom_bar(stat="identity") +
  facet_wrap(~collection) +
  theme_minimal() +
  theme(legend.title=element_text(size = 14, face = "bold")) +
  theme(legend.text=element_text(size = 12, face = "bold")) + 
  theme(axis.text=element_text(size=12, face = "bold"),axis.title=element_text(size=12, face = "bold")) +
  theme(strip.text.x = element_text(size = 11, face = "bold"), strip.text.y = element_text(size = 11, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  labs(y = "Number of domains in millions \n", x = "")

# collections as facets, only national archives
clean_domains_per_year  %>%
  filter(archive %in% c("bnf", "lwa", "szl")) %>% ### remember to include nak!
  ggplot(aes(x=year, y=count/1000000)) +
  geom_bar(stat="identity") +
  facet_wrap(~collection,ncol=2, labeller=labeller(collection = 
    c("bnf-all" = "BNF, all TLDs",
      "bnf-fr" = "BNF, only .fr",
      "lwa-all" = "LWA, all TLDs",
      "lwa-lu" = "LWA, only .lu",
      "szl-all" = "SZL, all TLDs",
      "szl-hu" = "SZL, only .hu"))) +
  theme_minimal() +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  labs(y = "Number of domains in millions \n", x = "")
# ncol sets the number of columns, add scales = "free_y" to facet_wrap for diff values on y-axes

# collections as facets, only ccTLDs
clean_domains_per_year %>%
  filter(country!="all") %>%
  filter(country!="dk") %>% # as long as we don't have the Danish data, delete filter when we have the data
  mutate(across(collection, factor, levels=c("bnf-fr","lwa-lu","szl-hu", "ia-fr", "ia-lu", "ia-hu","cc-fr", "cc-lu", "cc-hu"))) %>%
  ggplot(aes(x=year, y=count/1000000)) +
  geom_bar(stat="identity") +
  facet_wrap(~collection,ncol=3) + # add scales = "free_y" for different scales on y-axes
  theme_minimal() +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  labs(y = "Number of domains in millions \n", x = "")
# TO DO: add labels
  
# for only one condition: filter(archive=="bnf") for only bnf OR filter(archive!="bnf") for all archives except bnf (!= means not equal to)
```

# 3. Each ccTLD across all archives
Based on statc-distinct-lvl2-per-tld-per-year
# Preparation for all ccTLDs
```{r}
# read data using function
lvl2_per_tld_per_year <- read_data_files("data", "*distinct-lvl2-per-tld-per-year.csv", c("n")) %>% 
  separate(collection, c("archive", "country"), remove=FALSE) 

# rename the first instance in archive (row one, column 34) to year
lvl2_per_tld_per_year$archive[1] <- "year"

# nrow(lvl2_per_tld_per_year) # number of rows
# ncol(lvl2_per_tld_per_year) # number of columns
```

## 3 .lu
```{r}
# create dataframe for a country and clean data
lu_across_archives <- lvl2_per_tld_per_year %>% 
  subset(n == "lu" | archive == "year") %>% # select all that has lu and choose one of the columns with the years
  select(-c("n","collection","country")) %>% # remove the columns mentioned
  select(archive, everything()) # move the column year to the first column

# first data in 1996

# data cleaning and correcting class
lu_across_archives <- t(lu_across_archives) # transpose df
column_names <- lu_across_archives[1,] # create vector from row 1
colnames(lu_across_archives) <- column_names # use vector to assign column names
lu_across_archives <- lu_across_archives[-c(1:4),] # remove row 1-4 and 31-32 (archive names + years with no data)  
lu_across_archives <- data.frame(lu_across_archives)
lu_across_archives <- lu_across_archives %>% mutate(across(everything(), trimws)) # remove whitespace
lu_across_archives <- lu_across_archives %>% mutate_at(c("bnf","cc","ia","lwa","nak","szl"), as.numeric)
lu_across_archives$year <- as.factor(lu_across_archives$year)

# use str(lu_across_archives) to check that the years are factors and that the values are numeric

# create long format for ggplot
lu_across_archives_melt <- melt(lu_across_archives, 
                        id.var="year",
                        measure.vars = colnames(lu_across_archives)[! colnames(lu_across_archives) %in% c("year")],
                        variable.name = "archive", 
                        value.name = "n")

# sort colors and labels in the right order
line_colors_lu <- c("#aeaeae","#000000","#3a3a3a","#838383","#c9c9c9","#e5e5e5")
line_labels_lu <- c("Luxembourg Web Archive", "Internet Archive", "Common Crawl", "Bibliothèque nationale de France", "Netarkivet", "Hungary Web Archive")
line_types_lu <- c("solid","dashed","dotdash","twodash","dotted","longdash")

# reorder factors and plot (run without scale_colour_manual first to make sure the order is correct, then add)
lu_across_archives_melt %>%
  mutate(archive = fct_relevel(archive, "lwa", "ia", "cc", "bnf","nak","szl")) %>%
  ggplot(aes(x = year, y = n, group = archive)) +
  geom_line(aes(linetype=archive,color = archive), linewidth = 1.2) +
  theme_minimal() +
  theme(legend.position="bottom",
        legend.title=element_text(size = 12, face = "bold"),
        legend.text=element_text(size = 12, face = "bold"),
        legend.key.width=unit(2,"cm"), # makes the legend key (the example of the linetype used) longer
        axis.text=element_text(size=12, face = "bold"),
        axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_linetype_manual(values = line_types_lu, labels = line_labels_lu) +
  scale_color_manual(values = line_colors_lu, labels = line_labels_lu) +
  labs(y = "Number of .lu domains \n", x = "\n Year", color = "Archive", linetype = "Archive")
# to export: 1555 x 588 
## TO DO: ADD EXPLANATIONS TO THE CODE!!

# Subset with the numbers for BNF, NAK and SZL (first data in 2005)
# sort colors and labels in the right order (s for subset)
line_colors_lu_subset <- c("#c9c9c9","#e5e5e5","#838383")
line_labels_lu_subset <- c("Netarkivet", "Hungary Web Archive","Bibliothèque nationale de France")
line_types_lu_subset <- c("dotted","longdash","twodash")

lu_across_archives_melt %>% 
  filter(archive == "nak" | archive == "szl" | archive == "bnf") %>%
  mutate(archive = fct_relevel(archive,"nak","szl","bnf")) %>%
#  filter(!year %in% c("1996","1997","1998","1999","2000","2001","2002","2003","2004")) %>%
  filter(n>0) %>% # remove the years where there are no data
  ggplot(aes(x = year, y = n, group = archive)) +
  geom_point(color="darkgrey") + # added to be able to see BNF 
  geom_line(aes(linetype=archive,color = archive), linewidth = 1.2) +
  theme_minimal() +
  theme(legend.position="bottom",
        legend.title=element_text(size = 12, face = "bold"),
        legend.text=element_text(size = 12, face = "bold"),
        legend.key.width=unit(2,"cm"),
        axis.text=element_text(size=12, face = "bold"),
        axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_linetype_manual(values = line_types_lu_subset, labels = line_labels_lu_subset) +
  scale_color_manual(values = line_colors_lu_subset, labels = line_labels_lu_subset) +
  labs(y = "Number of .lu domains \n", x = "\n Year", color = "Archive", linetype = "Archive")
```

## 3 .fr
```{r}
# create dataframe for a country and clean data
fr_across_archives <- lvl2_per_tld_per_year %>% 
  subset(n == "fr" | archive == "year") %>%
  select(-c("n","collection","country")) %>%
  select(archive, everything())

# first data in 1993

# data cleaning and correcting class
fr_across_archives <- t(fr_across_archives) # transpose df
column_names <- fr_across_archives[1,] # create vector from row 1
colnames(fr_across_archives) <- column_names # use vector to assign column names
fr_across_archives <- fr_across_archives[-1,] # remove row 1 (archive names)  
fr_across_archives <- data.frame(fr_across_archives)
fr_across_archives <- fr_across_archives %>% mutate(across(everything(), trimws)) # remove whitespace
fr_across_archives <- fr_across_archives %>% mutate_at(c("bnf","cc","ia","lwa","nak","szl"), as.numeric)
fr_across_archives$year <- as.factor(fr_across_archives$year)

# use str(fr_across_archives) to check that the years are factors and that the values are numeric

# create long format for ggplot
fr_across_archives_melt <- melt(fr_across_archives, 
                        id.var="year",
                        measure.vars = colnames(fr_across_archives)[! colnames(fr_across_archives) %in% c("year")],
                        variable.name = "archive", 
                        value.name = "n")

# sort colors and labels in the right order
line_colors_fr <- c("#838383","#000000","#3a3a3a","#aeaeae","#c9c9c9","#e5e5e5")
line_labels_fr <- c("Bibliothèque nationale de France", "Internet Archive", "Common Crawl", "Luxembourg Web Archive", "Netarkivet", "Hungary Web Archive")
line_types_fr <- c("twodash","dashed","dotdash","solid","dotted","longdash")

# reorder factors and plot
fr_across_archives_melt %>% 
  mutate(archive = fct_relevel(archive,"bnf","ia", "cc","lwa","nak","szl")) %>%
  ggplot(aes(x = year, y = n, group = archive)) + 
  geom_line(aes(linetype=archive,color = archive), linewidth = 1.2) + 
  theme_minimal() +
  theme(legend.position="bottom",
        legend.title=element_text(size = 12, face = "bold"),
        legend.text=element_text(size = 12, face = "bold"),
        legend.key.width=unit(2,"cm"),
        axis.text=element_text(size=12, face = "bold"),
        axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_linetype_manual(values = line_types_fr, labels = line_labels_fr) +
  scale_color_manual(values = line_colors_fr, labels = line_labels_fr) +
  labs(y = "Number of .fr domains \n", x = "\n Year", color = "Archive", linetype = "Archive")

# Subset with the numbers for LWA, NAK and SZL (first data in 2003)
# sort colors and labels in the right order
line_colors_fr_subset <- c("#c9c9c9","#aeaeae","#e5e5e5")
line_labels_fr_subset <- c("Netarkivet", "Luxembourg Web Archive", "Hungary Web Archive")
line_types_fr_subset <- c("dotted","solid","longdash")

fr_across_archives_melt %>% 
  filter(archive == "nak" | archive == "lwa" | archive == "szl") %>%
  mutate(archive = fct_relevel(archive,"nak","lwa","szl")) %>%
#  filter(!year %in% c("1996","1997","1998","1999","2000","2001","2002","2003","2004")) %>%
  filter(n>0) %>% # remove the years where there are no data
  ggplot(aes(x = year, y = n, group = archive)) +
  geom_point(color="darkgrey") + # added to be able to see BNF 
  geom_line(aes(linetype=archive,color = archive), linewidth = 1.2) +
  theme_minimal() +
  theme(legend.position="bottom",
        legend.title=element_text(size = 12, face = "bold"),
        legend.text=element_text(size = 12, face = "bold"),
        legend.key.width=unit(2,"cm"),
        axis.text=element_text(size=12, face = "bold"),
        axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_linetype_manual(values = line_types_fr_subset, labels = line_labels_fr_subset) +
  scale_color_manual(values = line_colors_fr_subset, labels = line_labels_fr_subset) +
  labs(y = "Number of .fr domains \n", x = "\n Year", color = "Archive", linetype = "Archive")
```

## 3 .dk
```{r}
# create dataframe for a country and clean data
dk_across_archives <- lvl2_per_tld_per_year %>% 
  subset(n == "dk" | archive == "year") %>%
  select(-c("n","collection","country")) %>%
  select(archive, everything())

# first data in 1995

# data cleaning and correcting class
dk_across_archives <- t(dk_across_archives) # transpose df
column_names <- dk_across_archives[1,] # create vector from row 1
colnames(dk_across_archives) <- column_names # use vector to assign column names
dk_across_archives <- dk_across_archives[-c(1:3),] # remove row 1-4 (archive names + years with no data)  
dk_across_archives <- data.frame(dk_across_archives)
dk_across_archives <- dk_across_archives %>% mutate(across(everything(), trimws)) # remove whitespace
dk_across_archives <- dk_across_archives %>% mutate_at(c("bnf", "cc", "ia", "lwa","nak","szl"), as.numeric)
dk_across_archives$year <- as.factor(dk_across_archives$year)

# use str(dk_across_archives) to check that the years are factors and that the values are numeric

# create long format for ggplot
dk_across_archives_melt <- melt(dk_across_archives, 
                        id.var="year",
                        measure.vars = colnames(dk_across_archives)[! colnames(dk_across_archives) %in% c("year")],
                        variable.name = "archive", 
                        value.name = "n")

# sort colors and labels in the right order
line_colors_dk <- c("#c9c9c9","#000000","#3a3a3a","#838383","#aeaeae","#e5e5e5")
line_labels_dk <- c("Netarkivet","Internet Archive","Common Crawl","Bibliothèque nationale de France","Luxembourg Web Archive","Hungary Web Archive")
line_types_dk <- c("dotted","dashed","dotdash","twodash","solid","longdash")

# reorder factors and plot
dk_across_archives_melt %>% 
  mutate(archive = fct_relevel(archive,"nak","ia","cc","bnf","lwa","szl")) %>%
  ggplot(aes(x = year, y = n, group = archive)) + 
  geom_line(aes(linetype=archive,color = archive), linewidth = 1.2) + 
  theme_minimal() +
  theme(legend.position="bottom",
        legend.title=element_text(size = 12, face = "bold"),
        legend.text=element_text(size = 12, face = "bold"),
        legend.key.width=unit(2,"cm"),
        axis.text=element_text(size=12, face = "bold"),
        axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_linetype_manual(values = line_types_dk, labels = line_labels_dk) +
  scale_color_manual(values = line_colors_dk, labels = line_labels_dk) +
  labs(y = "Number of .dk domains \n", x = "\n Year", color = "Archive", linetype = "Archive")

# Subset with the numbers for LWA, BNF and SZL (first data in 2001)
# sort colors and labels in the right order
line_colors_dk_subset <- c("#aeaeae","#e5e5e5","#838383")
line_labels_dk_subset <- c("Luxembourg Web Archive","Hungary Web Archive","Bibliothèque nationale de France")
line_types_dk_subset <- c("solid","longdash","twodash")

dk_across_archives_melt %>% 
  filter(archive == "lwa" | archive == "szl" | archive == "bnf") %>%
  mutate(archive = fct_relevel(archive,"lwa","szl","bnf")) %>%
#  filter(!year %in% c("1996","1997","1998","1999","2000","2001","2002","2003","2004")) %>%
  filter(n>0) %>% # remove the years where there are no data
  ggplot(aes(x = year, y = n, group = archive)) +
  geom_point(color="darkgrey") + # added to be able to see BNF 
  geom_line(aes(linetype=archive,color = archive), linewidth = 1.2) +
  theme_minimal() +
  theme(legend.position="bottom",
        legend.title=element_text(size = 12, face = "bold"),
        legend.text=element_text(size = 12, face = "bold"),
        legend.key.width=unit(2,"cm"),
        axis.text=element_text(size=12, face = "bold"),
        axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_linetype_manual(values = line_types_dk_subset, labels = line_labels_dk_subset) +
  scale_color_manual(values = line_colors_dk_subset, labels = line_labels_dk_subset) +
  labs(y = "Number of .dk domains \n", x = "\n Year", color = "Archive", linetype = "Archive")
```

## 3 .hu
```{r}
# create dataframe for a country and clean data
hu_across_archives <- lvl2_per_tld_per_year %>% 
  subset(n == "hu" | archive == "year") %>%
  select(-c("n","collection","country")) %>%
  select(archive, everything())

# first data in 1996

# data cleaning and correcting class
hu_across_archives <- t(hu_across_archives) # transpose df
column_names <- hu_across_archives[1,] # create vector from row 1
colnames(hu_across_archives) <- column_names # use vector to assign column names
hu_across_archives <- hu_across_archives[-c(1:4),] # remove row 1-4 (archive names + years with no data)  
hu_across_archives <- data.frame(hu_across_archives)
hu_across_archives <- hu_across_archives %>% mutate(across(everything(), trimws)) # remove whitespace
hu_across_archives <- hu_across_archives %>% mutate_at(c("bnf", "cc", "ia", "lwa","nak","szl"), as.numeric)
hu_across_archives$year <- as.factor(hu_across_archives$year)

# use str(hu_across_archives) to check that the years are factors and that the values are numeric

# create long format for ggplot
hu_across_archives_melt <- melt(hu_across_archives, 
                        id.var="year",
                        measure.vars = colnames(hu_across_archives)[! colnames(hu_across_archives) %in% c("year")],
                        variable.name = "archive", 
                        value.name = "n")

# sort colors and labels in the right order
line_colors_hu <- c("#e5e5e5","#000000","#3a3a3a","#838383","#aeaeae","#c9c9c9")
line_labels_hu <- c("Hungary Web Archive","Internet Archive", "Common Crawl", "Bibliothèque nationale de France", "Luxembourg Web Archive", "Netarkivet")
line_types_hu <- c("longdash","dashed","dotdash","twodash","solid","dotted")

# reorder factors and plot
hu_across_archives_melt %>% 
  mutate(archive = fct_relevel(archive,"szl","ia","cc","bnf","lwa","nak")) %>%
  ggplot(aes(x = year, y = n, group = archive)) + 
  geom_line(aes(linetype=archive,color = archive), linewidth = 1.2) + 
  theme_minimal() +
  theme(legend.position="bottom",
        legend.title=element_text(size = 12, face = "bold"),
        legend.text=element_text(size = 12, face = "bold"),
        legend.key.width=unit(2,"cm"),
        axis.text=element_text(size=12, face = "bold"),
        axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_linetype_manual(values = line_types_hu, labels = line_labels_hu) +
  scale_color_manual(values = line_colors_hu, labels = line_labels_hu) +
  labs(y = "Number of .hu domains \n", x = "\n Year", color = "Archive", linetype = "Archive")

# Subset with the numbers for LWA, NAK and BNF (first data in 2001)
# sort colors and labels in the right order
line_colors_hu_subset <- c("#c9c9c9","#aeaeae","#838383")
line_labels_hu_subset <- c("Netarkivet", "Luxembourg Web Archive", "Bibliothèque nationale de France")
line_types_hu_subset <- c("dotted","solid","twodash")

hu_across_archives_melt %>% 
  filter(archive == "nak" | archive == "lwa" | archive == "bnf") %>%
  mutate(archive = fct_relevel(archive,"nak","lwa","bnf")) %>%
#  filter(!year %in% c("1996","1997","1998","1999","2000","2001","2002","2003","2004")) %>%
  filter(n>0) %>% # remove the years where there are no data
  ggplot(aes(x = year, y = n, group = archive)) +
  geom_point(color="darkgrey") + # added to be able to see BNF 
  geom_line(aes(linetype=archive,color = archive), linewidth = 1.2) +
  theme_minimal() +
  theme(legend.position="bottom",
        legend.title=element_text(size = 12, face = "bold"),
        legend.text=element_text(size = 12, face = "bold"),
        legend.key.width=unit(2,"cm"),
        axis.text=element_text(size=12, face = "bold"),
        axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_linetype_manual(values = line_types_hu_subset, labels = line_labels_hu_subset) +
  scale_color_manual(values = line_colors_hu_subset, labels = line_labels_hu_subset) +
  labs(y = "Number of .hu domains \n", x = "\n Year", color = "Archive", linetype = "Archive")
```

# 4. Top 15 TLDs in the different national archives
## Netarkivet - WRONG DATA
Based on statc-distinct-lvl2-per-tld-overall.
```{r}
# read data and add column names
dk_lvl2_per_tld <- read.csv("data/nak-dk-statc-distinct-lvl2-per-tld-overall.csv", header=FALSE) # It has no headers, so we add the column names
colnames(dk_lvl2_per_tld) = c("TLD","num_domains")

# to see the data to decide how many TLDs to include
head(dk_lvl2_per_tld, 20) # change the number depending on how many you want to see
  
# create top15 and an "Other" category with the rest
percentage_top15 <- dk_lvl2_per_tld %>% 
  arrange(desc(num_domains)) %>% # probably not necessary but just to make sure they are properly sorted
  split(c(rep("top", 15), rep("rest", nrow(.) - 15))) %>% # splits into the top 15 and the rest
  (\(s) bind_rows(s$top, data.frame(TLD = "Other", num_domains = sum(s$rest$num_domains)))) %>% # sums num_domains for all from the "other" category
  mutate(percentage = num_domains/sum(num_domains)) # creates a column with the percentages for each TLD and the Other category 

# plot with reorder to order descending based on percentage but with  
percentage_top15 %>% ggplot(aes(x=reorder(TLD, -percentage) %>% fct_relevel("Other", after = Inf), y=percentage)) + 
  geom_bar(stat="identity", fill="royalblue") +
  theme_minimal() +
  scale_y_continuous(labels = percent) +
  labs(y = "Percentage from different TLDs \n", x = "\n TLD")  

# -percentage means that the order is descending (based on num_domains)
# Inf er for infinite, so here it means that the Other category is placed at the end
# to plot it with Other where it is placed depending on descending num_domains, remove: %>% fct_relevel("Other", after = Inf)
```

## 4 Luxembourg Web Archive
Based on statc-distinct-lvl2-per-tld-overall.
```{r}
# read data and add column names
lwa_lvl2_per_tld <- read.csv("data/lwa-all-statc-distinct-lvl2-per-tld-overall.csv", header=FALSE) # It has no headers, so we add the column names
colnames(lwa_lvl2_per_tld) = c("TLD","num_domains")

# to see the data to decide how many TLDs to include
head(lwa_lvl2_per_tld, 20) # change the number depending on how many you want to see
  
# create top20 and an "Other" category with the rest
percentage_top20 <- lwa_lvl2_per_tld %>% 
  arrange(desc(num_domains)) %>% # probably not necessary but just to make sure they are properly sorted
  split(c(rep("top", 20), rep("rest", nrow(.) - 20))) %>% # splits into the top 15 and the rest
  (\(s) bind_rows(s$top, data.frame(TLD = "Other", num_domains = sum(s$rest$num_domains)))) %>% # sums num_domains for all from the "other" category
  mutate(percentage = num_domains/sum(num_domains)) # creates a column with the percentages for each TLD and the Other category 

# plot with reorder to order descending based on percentage but with  
percentage_top20 %>% ggplot(aes(x=reorder(TLD, -percentage) %>% fct_relevel("Other", after = Inf), y=percentage)) + 
  geom_bar(stat="identity", fill="deeppink2") +
  theme_minimal() +
  scale_y_continuous(labels = percent) +
  labs(y = "Percentage from different TLDs \n", x = "\n TLD")  

# -percentage means that the order is descending (based on num_domains)
# Inf er for infinite, so here it means that the Other category is placed at the end
# to plot it with Other where it is placed depending on descending num_domains, remove: %>% fct_relevel("Other", after = Inf)
```

## 4 BNF
Based on statc-distinct-lvl2-per-tld-overall.
```{r}
# read data and add column names
bnf_lvl2_per_tld <- read.csv("data/bnf-all-statc-distinct-lvl2-per-tld-overall.csv", header=FALSE) # It has no headers, so we add the column names
colnames(bnf_lvl2_per_tld) = c("TLD","num_domains")

# to see the data to decide how many TLDs to include
head(bnf_lvl2_per_tld, 20) # change the number depending on how many you want to see
  
# create top20 and an "Other" category with the rest
percentage_top20 <- bnf_lvl2_per_tld %>% 
  arrange(desc(num_domains)) %>% # probably not necessary but just to make sure they are properly sorted
  split(c(rep("top", 20), rep("rest", nrow(.) - 20))) %>% # splits into the top 15 and the rest
  (\(s) bind_rows(s$top, data.frame(TLD = "Other", num_domains = sum(s$rest$num_domains)))) %>% # sums num_domains for all from the "other" category
  mutate(percentage = num_domains/sum(num_domains)) # creates a column with the percentages for each TLD and the Other category 

# plot with reorder to order descending based on percentage but with  
percentage_top20 %>% ggplot(aes(x=reorder(TLD, -percentage) %>% fct_relevel("Other", after = Inf), y=percentage)) + 
  geom_bar(stat="identity", fill="gold") +
  theme_minimal() +
  scale_y_continuous(labels = percent) +
  labs(y = "Percentage from different TLDs \n", x = "\n TLD")  

# -percentage means that the order is descending (based on num_domains)
# Inf er for infinite, so here it means that the Other category is placed at the end
# to plot it with Other where it is placed depending on descending num_domains, remove: %>% fct_relevel("Other", after = Inf)
```

## 4 SZL
Based on statc-distinct-lvl2-per-tld-overall.
```{r}
# read data and add column names
szl_lvl2_per_tld <- read.csv("data/szl-all-statc-distinct-lvl2-per-tld-overall.csv", header=FALSE) # It has no headers, so we add the column names
colnames(szl_lvl2_per_tld) = c("TLD","num_domains")

# to see the data to decide how many TLDs to include
head(szl_lvl2_per_tld, 20) # change the number depending on how many you want to see
  
# create top20 and an "Other" category with the rest
percentage_top20 <- szl_lvl2_per_tld %>% 
  arrange(desc(num_domains)) %>% # probably not necessary but just to make sure they are properly sorted
  split(c(rep("top", 20), rep("rest", nrow(.) - 20))) %>% # splits into the top 15 and the rest
  (\(s) bind_rows(s$top, data.frame(TLD = "Other", num_domains = sum(s$rest$num_domains)))) %>% # sums num_domains for all from the "other" category
  mutate(percentage = num_domains/sum(num_domains)) # creates a column with the percentages for each TLD and the Other category 

# plot with reorder to order descending based on percentage but with  
percentage_top20 %>% ggplot(aes(x=reorder(TLD, -percentage) %>% fct_relevel("Other", after = Inf), y=percentage)) + 
  geom_bar(stat="identity", fill="darkorchid3") +
  theme_minimal() +
  scale_y_continuous(labels = percent) +
  labs(y = "Percentage from different TLDs \n", x = "\n TLD")  

# -percentage means that the order is descending (based on num_domains)
# Inf er for infinite, so here it means that the Other category is placed at the end
# to plot it with Other where it is placed depending on descending num_domains, remove: %>% fct_relevel("Other", after = Inf)
```

# 5. Overlap analysis
## LWA
Based on overlaps_hosts_lwa
```{r}
# read data
overlaps_hosts_lwa <- read_csv2("data_overlaps/overlaps_hosts_lwa.csv")

# create long format for ggplot
overlaps_hosts_lwa_melt <- melt(overlaps_hosts_lwa, 
                        id.var="Year",
                        measure.vars = colnames(overlaps_hosts_lwa)[! colnames(overlaps_hosts_lwa) %in% c("Year")],
                        variable.name = "Archive", 
                        value.name = "n")
# plot
overlaps_hosts_lwa_melt %>% ggplot(aes(x=Year, y=n, fill=Archive)) +
  geom_bar(stat="identity") +
  theme_minimal() +
  theme(legend.position="bottom") +
  theme(legend.title=element_text(size = 14, face = "bold")) +
  theme(legend.text=element_text(size = 12, face = "bold")) + 
  theme(axis.text=element_text(size=12, face = "bold"),axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_x_continuous(breaks = clean_domains_per_year$year) +
  scale_fill_manual(values = c("orange2","navyblue","deeppink2","aquamarine","cadetblue2","cornflowerblue","cyan"),
  labels = c("Common Crawl","Internet Archive","LWA","Internet Archive & Common Crawl","LWA & Common Crawl","LWA & Internet Archive","LWA & Internet Archive & Common Crawl")) + 
  labs(y = "Number of .dk domains \n", x = "\n Year", color = "Archive")

```

## BNF
Based on overlaps_hosts_bnf
```{r}
# read data
overlaps_hosts_bnf <- read_csv2("data_overlaps/overlaps_hosts_bnf.csv")

# create long format for ggplot
overlaps_hosts_bnf_melt <- melt(overlaps_hosts_bnf, 
                        id.var="Year",
                        measure.vars = colnames(overlaps_hosts_bnf)[! colnames(overlaps_hosts_bnf) %in% c("Year")],
                        variable.name = "Archive", 
                        value.name = "n")
# plot
overlaps_hosts_bnf_melt %>% ggplot(aes(x=Year, y=n, fill=Archive)) +
  geom_bar(stat="identity") +
  theme_minimal() +
  theme(legend.title=element_text(size = 14, face = "bold")) +
  theme(legend.text=element_text(size = 12, face = "bold")) + 
  theme(axis.text=element_text(size=12, face = "bold"),axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_x_continuous(breaks = clean_domains_per_year$year) +
  scale_fill_manual(values = c("orange2","navyblue","gold","aquamarine","cadetblue2","cornflowerblue","cyan"),
  labels = c("Common Crawl","Internet Archive","BNF","Internet Archive & Common Crawl","BNF & Common Crawl","BNF & Internet Archive","BNF & Internet Archive & Common Crawl")) + 
  labs(y = "Number of .dk domains \n", x = "\n Year", color = "Archive")
```

## SZL
Based on overlaps_hosts_szl
```{r}
# read data
overlaps_hosts_szl <- read_csv2("data/overlaps_hosts_hu.csv")

# create long format for ggplot
overlaps_hosts_szl_melt <- melt(overlaps_hosts_szl, 
                        id.var="Year",
                        measure.vars = colnames(overlaps_hosts_szl)[! colnames(overlaps_hosts_szl) %in% c("Year")],
                        variable.name = "Archive", 
                        value.name = "n")
# plot
overlaps_hosts_szl_melt %>% ggplot(aes(x=Year, y=n, fill=Archive)) +
  geom_bar(stat="identity") +
  theme_minimal() +
  theme(legend.title=element_text(size = 14, face = "bold")) +
  theme(legend.text=element_text(size = 12, face = "bold")) + 
  theme(axis.text=element_text(size=12, face = "bold"),axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_x_continuous(breaks = overlaps_hosts_szl$year) +
  scale_fill_manual(values = c("#aeaeae","#000000","#3a3a3a","#838383","#c9c9c9","#e5e5e5", "#121212")) +
#  scale_fill_manual(values = c("orange2","navyblue","darkorchid3","aquamarine","cadetblue2","cornflowerblue","cyan"), labels = c("Common Crawl","Internet Archive","SZL","Internet Archive & Common Crawl","SZL & Common Crawl","SZL & Internet Archive","SZL & Internet Archive & Common Crawl")) + 
  labs(y = "Number of .dk domains \n", x = "\n Year", color = "Archive")
```

# Bibliothèque nationale de France = "gold"
# Common Crawl = "orange2"
# Internet Archive = "navyblue"
# Luxembourg Web Archive = "deeppink2"
# Netarkivet = "red"
# Hungary Web Archive = "darkorchid3"

# Internet Archive + Common crawl: "aquamarine"
# National archive + Common crawl: "cadetblue2"
# National archive + Internet Archive: "cornflowerblue"
# National archive + Internet Archive + Common crawl: "cyan"

# "cadetblue2","cornflowerblue","aquamarine","blue","cyan","dodgerblue","navyblue"

## .dk - WRONG DATA!
```{r}
# read data
overlaps_hosts_dk <- read_csv2("data/overlaps_hosts_dk_2.csv")

# create long format for ggplot
overlaps_hosts_dk_melt <- melt(overlaps_hosts_dk, 
                        id.var="Year",
                        measure.vars = colnames(overlaps_hosts_dk)[! colnames(overlaps_hosts_dk) %in% c("Year")],
                        variable.name = "Archive", 
                        value.name = "n")
# plot
overlaps_hosts_dk_melt %>% ggplot(aes(x=Year, y=n, fill=Archive)) +
  geom_bar(stat="identity") +
  theme_minimal() +
  theme(legend.title=element_text(size = 16, face = "bold")) +
  theme(legend.text=element_text(size = 14, face = "bold")) + 
  theme(axis.text=element_text(size=14, face = "bold"),axis.title=element_text(size=16, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_x_continuous(breaks = clean_domains_per_year$year) +
  scale_fill_manual(values = c("cadetblue2","cornflowerblue","aquamarine","blue","cyan","dodgerblue","navyblue"),labels = c("Internet Archive","Common Crawl","Netarkivet","Internet Archive & Common Crawl","Netarkivet & Common Crawl","Netarkivet & Internet Archive","Netarkivet, Internet Archive & Common Crawl")) + 
  labs(y = "Number of .dk domains \n", x = "\n Year", color = "Archive")
```

# Distinct TLD per year in the national archives (not BNF)
Based on distinct-tld-per-year.csv
Because we only need the files from NAK, LWA & SZL (the ones with all), the others have been removed from the data folder
```{r}
# read files and add column names + column with archive name for
szl_tld_per_year <- read.csv("data/szl-all-statb-distinct-tld-per-year.csv", header = FALSE) 
colnames(szl_tld_per_year) <- c("year","n_tlds") # name columns
szl_tld_per_year <- szl_tld_per_year %>%
  mutate(archive="szl") # add column with archive name

lwa_tld_per_year <- read.csv("data/lwa-all-statb-distinct-tld-per-year.csv", header = FALSE) 
colnames(lwa_tld_per_year) <- c("year","n_tlds") # name columns
lwa_tld_per_year <- lwa_tld_per_year %>%
  mutate(archive="lwa") # add column with archive name

distinct_tlds_per_year <- rbind(szl_tld_per_year,lwa_tld_per_year)

ggplot(distinct_tlds_per_year, aes(x=year, y=n_tlds, group=archive, colour=archive)) + 
  geom_line(linewidth = 1.2) +
  theme_minimal() +
  theme(legend.title=element_text(size = 14, face = "bold")) +
  theme(legend.text=element_text(size = 12, face = "bold")) + 
  theme(axis.text=element_text(size=12, face = "bold"),axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_x_continuous(breaks = distinct_tlds_per_year$year) +
  scale_colour_manual(values = c("deeppink2","darkorchid3"), labels = c("Luxembourg Web Archive","Hungary Web Archive")) +
  labs(y = "Number of TLDs \n", x = "\n Year", color = "Archive") 

```

###  QUESTION: Do we need to plot the statc-distinct-lvl2-per-tld-per-year as well? This would show the changes over time!
```{r}
# read data
dk_lvl2_per_tld_per_year <- read_csv("data/nak-dk-statc-distinct-lvl2-per-tld-per-year.csv")
```

EXTRA

# Define colour scheme to use across the analysis
To use the same colours for the same archive each time
```{r}
# Bibliothèque nationale de France = "gold"
# Common Crawl = "orange2"
# Internet Archive = "navyblue"
# Luxembourg Web Archive = "deeppink2"
# Netarkivet = "red"
# Hungary Web Archive = "darkorchid3"

# other colours: "darkviolet","deeppink3","royalblue", "navyblue", "mediumpurple", "magenta", "violetred2", "orchid3"

# labels = c("Bibliothèque nationale de France","Common Crawl", "Internet Archive", "Luxembourg Web Archive", "Netarkivet", "Hungary Web Archive"))

# National Széchényi Library, NSZL Web Archive, OSZK Webarchívum
# Les archives de l’internet, BNF
```


###TEST COLOUR SCHEME
```{r}
cdx_colours <- c("black","gray20","grey40","grey60","grey80","grey95")
names(cdx_colours) <- c("IA","CC","NAK","LWA","BNF","SZL")

# hex: 
#000000
#3a3a3a	(58,58,58)
#838383	(131,131,131)
#aeaeae	(174,174,174)
#c9c9c9	(201,201,201)
#e5e5e5
```

# Knit to create pdf report
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
