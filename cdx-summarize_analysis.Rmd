---
title: "cdx-summarize_analysis"
output: html_document
date: "2023-05-16"
editor_options: 
  chunk_output_type: console
---
New version of the script started 16.05.2023 to include the analysis and visualizations for the chapter (and to clean up previous versions).
Work in progress!

NB: Change chunk input to inline in order to include them in the report if knitted

# Load libraries
```{r}
# install.packages(c("pacman","tidyverse","here","fs","ggplot2","reshape2","scales","ggpattern"))

pacman::p_load(tidyverse,here,fs,ggplot2,reshape2,scales,ggpattern)
# here() makes it easy to access data and files in the project directory thereby avoiding 
# using pull paths
# fs is for file system stuff, e.g., dir_ls
# scales is used to show percentage on the y axis
```

# Set working directory
```{r}
setwd("/Users/au148767/R_Projects/warcnet-cdx-summarize-analysis/")
```

### TO DO: Explain how we get from the summary files to the files with stat a, b, c and the overlap analyses. Are all the stats done with the warcnetstats.py script?

# Comments on the data
Most of the data used are what we have called statistics a, b and c (IS IT CREATED USING THE SCRIPT warcnetstats.py?). The statistics are the number of distinct domains, distinct top-level domains and distinct second-level domains, and for each we include the total number (called "overall") and the number per year. There are six different web archives involved: four national archives and two international archives. For the national archives, we have the three statistics both for everything in the archive ("all") and for just the nation's ccTLD (dk, fr, hu, and lu, respectively), resulting in a total of 12 files per archive. For the international archives, we have each of the four ccTLDs mentioned, resulting in 24 files per archive. This results in a total of 96 files.
However, not all the statistics are relevant for each archive. The stats from the international archives only include one tld, hence it does not make sense to look at statistics b (tld) for IA and CC. In the same way, statistics b for the ccTLD version of the national archives are irrelevant. This removes 16 + 8 = 24 files.
We also have to think about duplicates, since some of the files include numbers that are the same or part of the same. Statistics c (lvl2-per-tld) from the ccTLD version of the national archive stats are already included in the file with the "overall" data from the same archive, so we need to remove these files to not get duplicates, when we do analysis based on stat c (here, Analysis 3: Each ccTLD across all archives). This removes 8 files.
For the overlap analysis, we have 4 files (HOW ARE THESE CREATED?), leaving a total of 68 files.
If you need to see a list of the files in the data folder, use list.files("data/").

# Create read files function
A function for loading a set of cvs files into a dataframe while including (part of) the filename in a column (name "collection").
```{r}
read_data_files <- function(folder, glob_expression, col_names) {
  dir_ls(here(folder), glob = glob_expression) %>% 
    map_dfr(
      \(filename) {
        print(filename);
        read_csv(filename, col_names = col_names)  %>%
          add_column(
            collection = paste(str_split(basename(filename),"-",simplify = T)[1:2], collapse = "-")
          )
      }
    )
}
```

# Colors & linetypes
"Internet Archive" : "#000000" : "dashed"
"Common Crawl" : "#e5e5e5" : "solid" 
"Bibliothèque nationale de France" : "#838383" : "twodash"
"Luxembourg Web Archive" : "#aeaeae" : "dotdash"
"Netarkivet" : "#c9c9c9" : "dotted"
"Hungary Web Archive" : "#3a3a3a" : "longdash"

# Total number of distinct domains from all countries and archives
Based on stata-distinct-domains-overall
```{r}
# read files with distinct domains overall (only one number)
distinct_domains_overall <- read_data_files("data", "*distinct-domains-overall.csv", c("n")) %>% 
  separate(collection, c("archive", "country"), remove=FALSE) # create columns with archive and country based on file name

# write to csv (optional)
# write_csv(distinct_domains_overall, "results/distinct_domains_overall.csv")
```

# Figure 1: Number of domains shown as facets (new version with each archive/ccTLD separately)
```{r}
# read files and remove years that are errors
clean_domains_per_year <- read_data_files("data","*domains-per-year.csv", c("year", "count")) %>%  
  filter(year > 1992)  %>%
  filter(year < 2022) %>% 
  separate(collection, c("archive", "country"), remove=FALSE)

# to see how many years are represented for each country in each archive 
# clean_domains_per_year %>% count(archive, country)

# rename to have correct labels
clean_domains_per_year$collection = toupper(clean_domains_per_year$collection) # capitalize all letters

clean_domains_per_year <- clean_domains_per_year %>% 
  mutate(collection = str_replace(collection, "-DK", " .dk")) %>%
  mutate(collection = str_replace(collection, "-FR", " .fr")) %>%
  mutate(collection = str_replace(collection, "-HU", " .hu")) %>%
  mutate(collection = str_replace(collection, "-LU", " .lu")) %>% 
  mutate(collection = str_replace(collection, "-ALL", " all TLDs")) 

# NAK & .dk - collections as facets
dk_facets <- clean_domains_per_year  %>%
  filter(archive=="nak"|country == "dk")

dk_facets$collection <- as.factor(dk_facets$collection)
  
dk_facets %>%   
  mutate(collection = fct_relevel(collection,"NAK all TLDs","NAK .dk","IA .dk","CC .dk")) %>% # previously "nak-all","nak-dk","ia-dk","cc-dk"
  ggplot(aes(x=year, y=count/1000000)) +
  geom_bar(stat="identity") +
  facet_wrap(~collection,nrow=1) +
  theme_minimal() +
  theme(axis.title=element_text(size=16, face = "bold"),
        axis.text=element_text(size=14, face = "bold"),
        strip.text = element_text(size = 20)) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  labs(y = "Number of domains in millions \n", x = "")

# BNF & .fr - collections as facets
fr_facets <- clean_domains_per_year  %>%
  filter(archive=="bnf"|country == "fr")

fr_facets$collection <- as.factor(fr_facets$collection)
  
fr_facets %>%   
  mutate(collection = fct_relevel(collection,"BNF all TLDs","BNF .fr","IA .fr","CC .fr")) %>%
  ggplot(aes(x=year, y=count/1000000)) +
  geom_bar(stat="identity") +
  facet_wrap(~collection,nrow=1) +
  theme_minimal() +
  theme(axis.title=element_text(size=16, face = "bold"),
        axis.text=element_text(size=14, face = "bold"),
        strip.text = element_text(size = 20)) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  labs(y = "Number of domains in millions \n", x = "")

# SZL & .hu - collections as facets
hu_facets <- clean_domains_per_year  %>%
  filter(archive=="szl"|country == "hu")

hu_facets$collection <- as.factor(hu_facets$collection)
  
hu_facets %>%   
  mutate(collection = fct_relevel(collection,"SZL all TLDs","SZL .hu","IA .hu","CC .hu")) %>%
  ggplot(aes(x=year, y=count/1000000)) +
  geom_bar(stat="identity") +
  facet_wrap(~collection,nrow=1) +
  theme_minimal() +
  theme(axis.title=element_text(size=16, face = "bold"),
        axis.text=element_text(size=14, face = "bold"),
        strip.text = element_text(size = 20)) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  labs(y = "Number of domains in millions \n", x = "")

# LWA & .lu - collections as facets
lu_facets <- clean_domains_per_year  %>%
  filter(archive=="lwa"|country == "lu")

lu_facets$collection <- as.factor(lu_facets$collection)
  
lu_facets %>%   
  mutate(collection = fct_relevel(collection,"LWA all TLDs","LWA .lu","IA .lu","CC .lu")) %>%
  ggplot(aes(x=year, y=count/1000000)) +
  geom_bar(stat="identity") +
  facet_wrap(~collection,nrow=1) +
  theme_minimal() +
  theme(axis.title=element_text(size=16, face = "bold"),
        axis.text=element_text(size=14, face = "bold"),
        strip.text = element_text(size = 20)) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  labs(y = "Number of domains in millions \n", x = "")
```

# Figure 2: Each ccTLD across all archives
Based on statc-distinct-lvl2-per-tld-per-year
# Preparation for all ccTLDs
```{r}
# read data using function
lvl2_per_tld_per_year <- read_data_files("data", "*distinct-lvl2-per-tld-per-year.csv", c("n")) %>% 
  separate(collection, c("archive", "country"), remove=FALSE) 

# rename the first instance in archive (row one, column 34) to year
lvl2_per_tld_per_year$archive[1] <- "year"

# nrow(lvl2_per_tld_per_year) # number of rows
# ncol(lvl2_per_tld_per_year) # number of columns
```

### Test with new layout
linewidth 1.5 (before 1.2)
text size 14 (before 12)
size 1550 x 550

- I am unsure if I should change the colour of CC - it is not very easy to see?! 
And maybe the color scheme doesn't matter as much, if we only include select plots?

## Fig 2 .dk
```{r}
# create dataframe for a country and clean data
dk_across_archives <- lvl2_per_tld_per_year %>% 
  subset(n == "dk" | archive == "year") %>%
  select(-c("n","collection","country")) %>%
  select(archive, everything())

# data cleaning and correcting class (first data in 1995)
dk_across_archives <- t(dk_across_archives) # transpose df
column_names <- dk_across_archives[1,] # create vector from row 1
colnames(dk_across_archives) <- column_names # use vector to assign column names
dk_across_archives <- dk_across_archives[-c(1:3),] # remove row 1-4 (archive names + years with no data)  
dk_across_archives <- data.frame(dk_across_archives)
dk_across_archives <- dk_across_archives %>% mutate(across(everything(), trimws)) # remove whitespace
dk_across_archives <- dk_across_archives %>% mutate_at(c("bnf", "cc", "ia", "lwa","nak","szl"), as.numeric)
dk_across_archives$year <- as.factor(dk_across_archives$year)

# write to csv (optional)
# write_csv(dk_across_archives, "results/dk_across_archives.csv")

# use str(dk_across_archives) to check that the years are factors and that the values are numeric

# create long format for ggplot
dk_across_archives_melt <- melt(dk_across_archives, 
                        id.var="year",
                        measure.vars = colnames(dk_across_archives)[! colnames(dk_across_archives) %in% c("year")],
                        variable.name = "archive", 
                        value.name = "n")

# sort colors and labels in the right order
line_colors_dk <- c("#c9c9c9","#000000","#e5e5e5","#838383","#aeaeae","#3a3a3a")
line_labels_dk <- c("Netarkivet","Internet Archive","Common Crawl","Bibliothèque nationale de France","Luxembourg Web Archive","Hungary Web Archive")
line_types_dk <- c("dotted","dashed","solid","twodash","dotdash","longdash")

# reorder factors and plot
dk_across_archives_melt %>% 
  mutate(archive = fct_relevel(archive,"nak","ia","cc","bnf","lwa","szl")) %>%
  ggplot(aes(x = year, y = n, group = archive)) + 
  geom_line(aes(linetype=archive,color = archive), linewidth = 1.5) + 
  theme_minimal() +
  theme(legend.position="top",
        legend.title=element_text(size = 14, face = "bold"),
        legend.text=element_text(size = 18, face = "bold"),
        legend.key.width=unit(3.5,"cm"),
        axis.text=element_text(size=14, face = "bold"),
        axis.title=element_text(size=22, face = "bold"),
        axis.title.x=element_blank()) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_linetype_manual(values = line_types_dk, labels = line_labels_dk) +
  scale_color_manual(values = line_colors_dk, labels = line_labels_dk) +
  labs(y = "Number of .dk domains \n", color = "Archive", linetype = "Archive")

# Subset with the numbers for LWA, BNF and SZL (first data in 2001)
# sort colors and labels in the right order
line_colors_dk_subset <- c("#aeaeae","#3a3a3a","#838383")
line_labels_dk_subset <- c("Luxembourg Web Archive","Hungary Web Archive","Bibliothèque nationale de France")
line_types_dk_subset <- c("dotdash","longdash","twodash")

dk_across_archives_melt %>% 
  filter(archive == "lwa" | archive == "szl" | archive == "bnf") %>%
  mutate(archive = fct_relevel(archive,"lwa","szl","bnf")) %>%
#  filter(!year %in% c("1996","1997","1998","1999","2000","2001","2002","2003","2004")) %>%
  filter(n>0) %>% # remove the years where there are no data
  ggplot(aes(x = year, y = n, group = archive)) +
  geom_point(color="darkgrey") + # added to be able to see BNF 
  geom_line(aes(linetype=archive,color = archive), linewidth = 1.2) +
  theme_minimal() +
  theme(legend.position="bottom",
        legend.title=element_text(size = 12, face = "bold"),
        legend.text=element_text(size = 12, face = "bold"),
        legend.key.width=unit(2,"cm"),
        axis.text=element_text(size=12, face = "bold"),
        axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_linetype_manual(values = line_types_dk_subset, labels = line_labels_dk_subset) +
  scale_color_manual(values = line_colors_dk_subset, labels = line_labels_dk_subset) +
  labs(y = "Number of .dk domains \n", x = "\n Year", color = "Archive", linetype = "Archive")
```

## Fig 2 .fr
```{r}
# create dataframe for a country and clean data
fr_across_archives <- lvl2_per_tld_per_year %>% 
  subset(n == "fr" | archive == "year") %>%
  select(-c("n","collection","country")) %>%
  select(archive, everything())

# data cleaning and correcting class (first data in 1993)
fr_across_archives <- t(fr_across_archives) # transpose df
column_names <- fr_across_archives[1,] # create vector from row 1
colnames(fr_across_archives) <- column_names # use vector to assign column names
fr_across_archives <- fr_across_archives[-1,] # remove row 1 (archive names)  
fr_across_archives <- data.frame(fr_across_archives)
fr_across_archives <- fr_across_archives %>% mutate(across(everything(), trimws)) # remove whitespace
fr_across_archives <- fr_across_archives %>% mutate_at(c("bnf","cc","ia","lwa","nak","szl"), as.numeric)
fr_across_archives$year <- as.factor(fr_across_archives$year)

# write to csv (optional)
# write_csv(fr_across_archives, "results/fr_across_archives.csv")

# use str(fr_across_archives) to check that the years are factors and that the values are numeric

# create long format for ggplot
fr_across_archives_melt <- melt(fr_across_archives, 
                        id.var="year",
                        measure.vars = colnames(fr_across_archives)[! colnames(fr_across_archives) %in% c("year")],
                        variable.name = "archive", 
                        value.name = "n")

# sort colors and labels in the right order
line_colors_fr <- c("#838383","#000000","#e5e5e5","#aeaeae","#c9c9c9","#3a3a3a")
line_labels_fr <- c("Bibliothèque nationale de France", "Internet Archive", "Common Crawl", "Luxembourg Web Archive", "Netarkivet", "Hungary Web Archive")
line_types_fr <- c("twodash","dashed","solid","dotdash","dotted","longdash")

# reorder factors and plot
fr_across_archives_melt %>% 
  mutate(archive = fct_relevel(archive,"bnf","ia", "cc","lwa","nak","szl")) %>%
  ggplot(aes(x = year, y = n, group = archive)) + 
  geom_line(aes(linetype=archive,color = archive), linewidth = 1.5) + 
  theme_minimal() +
  theme(legend.position="none",
        legend.title=element_text(size = 14, face = "bold"),
        legend.text=element_text(size = 14, face = "bold"),
        legend.key.width=unit(2,"cm"),
        axis.text=element_text(size=14, face = "bold"),
        axis.title=element_text(size=22, face = "bold"),
        axis.title.x=element_blank()) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_linetype_manual(values = line_types_fr, labels = line_labels_fr) +
  scale_color_manual(values = line_colors_fr, labels = line_labels_fr) +
  labs(y = "Number of .fr domains \n", color = "Archive", linetype = "Archive")

# Subset with the numbers for LWA, NAK and SZL (first data in 2003)
# sort colors and labels in the right order
line_colors_fr_subset <- c("#c9c9c9","#aeaeae","#3a3a3a")
line_labels_fr_subset <- c("Netarkivet", "Luxembourg Web Archive", "Hungary Web Archive")
line_types_fr_subset <- c("dotted","dotdash","longdash")

fr_across_archives_melt %>% 
  filter(archive == "nak" | archive == "lwa" | archive == "szl") %>%
  mutate(archive = fct_relevel(archive,"nak","lwa","szl")) %>%
#  filter(!year %in% c("1996","1997","1998","1999","2000","2001","2002","2003","2004")) %>%
  filter(n>0) %>% # remove the years where there are no data
  ggplot(aes(x = year, y = n, group = archive)) +
  geom_point(color="darkgrey") + # added to be able to see BNF 
  geom_line(aes(linetype=archive,color = archive), linewidth = 1.2) +
  theme_minimal() +
  theme(legend.position="bottom",
        legend.title=element_text(size = 12, face = "bold"),
        legend.text=element_text(size = 12, face = "bold"),
        legend.key.width=unit(2,"cm"),
        axis.text=element_text(size=12, face = "bold"),
        axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_linetype_manual(values = line_types_fr_subset, labels = line_labels_fr_subset) +
  scale_color_manual(values = line_colors_fr_subset, labels = line_labels_fr_subset) +
  labs(y = "Number of .fr domains \n", x = "\n Year", color = "Archive", linetype = "Archive")
```

## Fig 2 .hu
```{r}
# create dataframe for a country and clean data
hu_across_archives <- lvl2_per_tld_per_year %>% 
  subset(n == "hu" | archive == "year") %>%
  select(-c("n","collection","country")) %>%
  select(archive, everything())

# data cleaning and correcting class (first data in 1996)
hu_across_archives <- t(hu_across_archives) # transpose df
column_names <- hu_across_archives[1,] # create vector from row 1
colnames(hu_across_archives) <- column_names # use vector to assign column names
hu_across_archives <- hu_across_archives[-c(1:4),] # remove row 1-4 (archive names + years with no data)  
hu_across_archives <- data.frame(hu_across_archives)
hu_across_archives <- hu_across_archives %>% mutate(across(everything(), trimws)) # remove whitespace
hu_across_archives <- hu_across_archives %>% mutate_at(c("bnf", "cc", "ia", "lwa","nak","szl"), as.numeric)
hu_across_archives$year <- as.factor(hu_across_archives$year)

# write to csv (optional)
# write_csv(hu_across_archives, "results/hu_across_archives.csv")

# use str(hu_across_archives) to check that the years are factors and that the values are numeric

# create long format for ggplot
hu_across_archives_melt <- melt(hu_across_archives, 
                        id.var="year",
                        measure.vars = colnames(hu_across_archives)[! colnames(hu_across_archives) %in% c("year")],
                        variable.name = "archive", 
                        value.name = "n")

# sort colors and labels in the right order
line_colors_hu <- c("#3a3a3a","#000000","#e5e5e5","#838383","#aeaeae","#c9c9c9")
line_labels_hu <- c("Hungary Web Archive","Internet Archive", "Common Crawl", "Bibliothèque nationale de France", "Luxembourg Web Archive", "Netarkivet")
line_types_hu <- c("longdash","dashed","solid","twodash","dotdash","dotted")

# reorder factors and plot
hu_across_archives_melt %>% 
  mutate(archive = fct_relevel(archive,"szl","ia","cc","bnf","lwa","nak")) %>%
  ggplot(aes(x = year, y = n, group = archive)) + 
  geom_line(aes(linetype=archive,color = archive), linewidth = 1.5) + 
  theme_minimal() +
  theme(legend.position="none",
        legend.title=element_text(size = 14, face = "bold"),
        legend.text=element_text(size = 14, face = "bold"),
        legend.key.width=unit(2,"cm"),
        axis.text=element_text(size=14, face = "bold"),
        axis.title=element_text(size=22, face = "bold"),
        axis.title.x=element_blank()) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_linetype_manual(values = line_types_hu, labels = line_labels_hu) +
  scale_color_manual(values = line_colors_hu, labels = line_labels_hu) +
  labs(y = "Number of .hu domains \n", x = "\n Year", color = "Archive", linetype = "Archive")

# Subset with the numbers for LWA, NAK and BNF (first data in 2001)
# sort colors and labels in the right order
line_colors_hu_subset <- c("#c9c9c9","#aeaeae","#838383")
line_labels_hu_subset <- c("Netarkivet", "Luxembourg Web Archive", "Bibliothèque nationale de France")
line_types_hu_subset <- c("dotted","dotdash","twodash")

hu_across_archives_melt %>% 
  filter(archive == "nak" | archive == "lwa" | archive == "bnf") %>%
  mutate(archive = fct_relevel(archive,"nak","lwa","bnf")) %>%
#  filter(!year %in% c("1996","1997","1998","1999","2000","2001","2002","2003","2004")) %>%
  filter(n>0) %>% # remove the years where there are no data
  ggplot(aes(x = year, y = n, group = archive)) +
  geom_point(color="darkgrey") + # added to be able to see BNF 
  geom_line(aes(linetype=archive,color = archive), linewidth = 1.2) +
  theme_minimal() +
  theme(legend.position="bottom",
        legend.title=element_text(size = 12, face = "bold"),
        legend.text=element_text(size = 12, face = "bold"),
        legend.key.width=unit(2,"cm"),
        axis.text=element_text(size=12, face = "bold"),
        axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_linetype_manual(values = line_types_hu_subset, labels = line_labels_hu_subset) +
  scale_color_manual(values = line_colors_hu_subset, labels = line_labels_hu_subset) +
  labs(y = "Number of .hu domains \n", x = "\n Year", color = "Archive", linetype = "Archive")
```

## Fig 2 .lu
```{r}
# create dataframe for a country and clean data
lu_across_archives <- lvl2_per_tld_per_year %>% 
  subset(n == "lu" | archive == "year") %>% # select all that has lu and choose one of the columns with the years
  select(-c("n","collection","country")) %>% # remove the columns mentioned
  select(archive, everything()) # move the column year to the first column

# data cleaning and correcting class (first data in 1996)
lu_across_archives <- t(lu_across_archives) # transpose df
column_names <- lu_across_archives[1,] # create vector from row 1
colnames(lu_across_archives) <- column_names # use vector to assign column names
lu_across_archives <- lu_across_archives[-c(1:4),] # remove row 1-4 and 31-32 (archive names + years with no data)  
lu_across_archives <- data.frame(lu_across_archives)
lu_across_archives <- lu_across_archives %>% mutate(across(everything(), trimws)) # remove whitespace
lu_across_archives <- lu_across_archives %>% mutate_at(c("bnf","cc","ia","lwa","nak","szl"), as.numeric)
lu_across_archives$year <- as.factor(lu_across_archives$year)

# write to csv (optional)
# write_csv(lu_across_archives, "results/lu_across_archives.csv")

# use str(lu_across_archives) to check that the years are factors and that the values are numeric

# create long format for ggplot
lu_across_archives_melt <- melt(lu_across_archives, 
                        id.var="year",
                        measure.vars = colnames(lu_across_archives)[! colnames(lu_across_archives) %in% c("year")],
                        variable.name = "archive", 
                        value.name = "n")

# sort colors and labels in the right order
line_colors_lu <- c("#aeaeae","#000000","#e5e5e5","#838383","#c9c9c9","#3a3a3a")
line_labels_lu <- c("Luxembourg Web Archive", "Internet Archive", "Common Crawl", "Bibliothèque nationale de France", "Netarkivet", "Hungary Web Archive")
line_types_lu <- c("dotdash","dashed","solid","twodash","dotted","longdash")

# reorder factors and plot (run without scale_colour_manual first to make sure the order is correct, then add)
lu_across_archives_melt %>%
  mutate(archive = fct_relevel(archive, "lwa", "ia", "cc", "bnf","nak","szl")) %>%
  ggplot(aes(x = year, y = n, group = archive)) +
  geom_line(aes(linetype=archive,color = archive), linewidth = 1.5) +
  theme_minimal() +
  theme(legend.position="none",
        legend.title=element_text(size = 14, face = "bold"),
        legend.text=element_text(size = 14, face = "bold"),
        legend.key.width=unit(2,"cm"), # makes the legend key (the example of the linetype used) longer
        axis.text=element_text(size=14, face = "bold"),
        axis.title=element_text(size=22, face = "bold"),
        axis.title.x=element_blank()) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_linetype_manual(values = line_types_lu, labels = line_labels_lu) +
  scale_color_manual(values = line_colors_lu, labels = line_labels_lu) +
  labs(y = "Number of .lu domains \n", x = "\n Year", color = "Archive", linetype = "Archive")
# to export: 1555 x 588 
## TO DO: ADD EXPLANATIONS TO THE CODE!!

# Subset with the numbers for BNF, NAK and SZL (first data in 2005)
# sort colors and labels in the right order (s for subset)
line_colors_lu_subset <- c("#c9c9c9","#3a3a3a","#838383")
line_labels_lu_subset <- c("Netarkivet", "Hungary Web Archive","Bibliothèque nationale de France")
line_types_lu_subset <- c("dotted","longdash","twodash")

lu_across_archives_melt %>% 
  filter(archive == "nak" | archive == "szl" | archive == "bnf") %>%
  mutate(archive = fct_relevel(archive,"nak","szl","bnf")) %>%
#  filter(!year %in% c("1996","1997","1998","1999","2000","2001","2002","2003","2004")) %>%
  filter(n>0) %>% # remove the years where there are no data
  ggplot(aes(x = year, y = n, group = archive)) +
  geom_point(color="darkgrey") + # added to be able to see BNF 
  geom_line(aes(linetype=archive,color = archive), linewidth = 1.2) +
  theme_minimal() +
  theme(legend.position="bottom",
        legend.title=element_text(size = 12, face = "bold"),
        legend.text=element_text(size = 12, face = "bold"),
        legend.key.width=unit(2,"cm"),
        axis.text=element_text(size=12, face = "bold"),
        axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_linetype_manual(values = line_types_lu_subset, labels = line_labels_lu_subset) +
  scale_color_manual(values = line_colors_lu_subset, labels = line_labels_lu_subset) +
  labs(y = "Number of .lu domains \n", x = "\n Year", color = "Archive", linetype = "Archive")
```


## Test: plotting the curves for IA together to see if there is any pattern?
If we want to use this, the colors, linetypes and labels should be changed to match the order!
```{r}
# create dataframe for a country and clean data
IA_all_ccTLDs <- lvl2_per_tld_per_year %>% 
  subset(archive == "ia" | archive == "year") %>%
  select(-c("collection","country")) %>%
  select(archive, everything())

# data cleaning and correcting class (first data in 1995)
IA_all_ccTLDs$n[1] <- "year"
IA_all_ccTLDs <- IA_all_ccTLDs %>% 
  subset(n != "tld") %>%
  select(-c("archive"))
IA_all_ccTLDs <- t(IA_all_ccTLDs) # transpose df
column_names <- IA_all_ccTLDs[1,] # create vector from row 1
colnames(IA_all_ccTLDs) <- column_names # use vector to assign column names
IA_all_ccTLDs <- IA_all_ccTLDs[-c(1),] # remove row 1 (archive names)  
IA_all_ccTLDs <- data.frame(IA_all_ccTLDs)
IA_all_ccTLDs <- IA_all_ccTLDs %>% mutate(across(everything(), trimws)) # remove whitespace
IA_all_ccTLDs <- IA_all_ccTLDs %>% mutate_at(c("dk", "fr", "hu", "lu"), as.numeric)
IA_all_ccTLDs$year <- as.factor(IA_all_ccTLDs$year)

# write to csv (optional)
# write_csv(IA_all_ccTLDs, "results/IA_all_ccTLDs")

# use str(IA_all_ccTLDs) to check that the years are factors and that the values are numeric

# create long format for ggplot
IA_all_ccTLDs_melt <- melt(IA_all_ccTLDs, 
                        id.var="year",
                        measure.vars = colnames(IA_all_ccTLDs)[! colnames(IA_all_ccTLDs) %in% c("year")],
                        variable.name = "archive", 
                        value.name = "n")

# sort colors and labels in the right order
# line_colors_dk <- c("#c9c9c9","#000000","#e5e5e5","#838383","#aeaeae","#3a3a3a")
# line_labels_dk <- c("Netarkivet","Internet Archive","Common Crawl","Bibliothèque nationale de France","Luxembourg Web Archive","Hungary Web Archive")
# line_types_dk <- c("dotted","dashed","solid","twodash","dotdash","longdash")

# reorder factors and plot
IA_all_ccTLDs_melt %>% 
#  mutate(archive = fct_relevel(archive,"dk","fr","hu","lu")) %>%
  ggplot(aes(x = year, y = n, group = archive)) + 
  geom_line(aes(linetype=archive,color = archive), linewidth = 1.2) + 
  theme_minimal() +
  theme(legend.position="bottom",
        legend.title=element_text(size = 12, face = "bold"),
        legend.text=element_text(size = 12, face = "bold"),
        legend.key.width=unit(2,"cm"),
        axis.text=element_text(size=12, face = "bold"),
        axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
#  scale_linetype_manual(values = line_types_dk, labels = line_labels_dk) +
#  scale_color_manual(values = line_colors_dk, labels = line_labels_dk) +
  labs(y = "Number of .dk domains \n", x = "\n Year", color = "Archive", linetype = "Archive")
```

## TEST, same for CC
```{r}
# create dataframe for a country and clean data
CC_all_ccTLDs <- lvl2_per_tld_per_year %>% 
  subset(archive == "cc" | archive == "year") %>%
  select(-c("collection","country")) %>%
  select(archive, everything())

# data cleaning and correcting class (first data in 1995)
CC_all_ccTLDs$n[1] <- "year"
CC_all_ccTLDs <- CC_all_ccTLDs %>% 
  subset(n != "tld") %>%
  select(-c("archive"))
CC_all_ccTLDs <- t(CC_all_ccTLDs) # transpose df
column_names <- CC_all_ccTLDs[1,] # create vector from row 1
colnames(CC_all_ccTLDs) <- column_names # use vector to assign column names
CC_all_ccTLDs <- CC_all_ccTLDs[-c(1:8),] # remove row 1 (archive names)  
CC_all_ccTLDs <- data.frame(CC_all_ccTLDs)
CC_all_ccTLDs <- CC_all_ccTLDs %>% mutate(across(everything(), trimws)) # remove whitespace
CC_all_ccTLDs <- CC_all_ccTLDs %>% mutate_at(c("dk", "fr", "hu", "lu"), as.numeric)
CC_all_ccTLDs$year <- as.factor(CC_all_ccTLDs$year)

# write to csv (optional)
# write_csv(CC_all_ccTLDs, "results/CC_all_ccTLDs")

# use str(CC_all_ccTLDs) to check that the years are factors and that the values are numeric

# create long format for ggplot
CC_all_ccTLDs_melt <- melt(CC_all_ccTLDs, 
                        id.var="year",
                        measure.vars = colnames(CC_all_ccTLDs)[! colnames(CC_all_ccTLDs) %in% c("year")],
                        variable.name = "archive", 
                        value.name = "n")

# sort colors and labels in the right order
# line_colors_dk <- c("#c9c9c9","#000000","#e5e5e5","#838383","#aeaeae","#3a3a3a")
# line_labels_dk <- c("Netarkivet","Internet Archive","Common Crawl","Bibliothèque nationale de France","Luxembourg Web Archive","Hungary Web Archive")
# line_types_dk <- c("dotted","dashed","solid","twodash","dotdash","longdash")

# reorder factors and plot
CC_all_ccTLDs_melt %>% 
#  mutate(archive = fct_relevel(archive,"dk","fr","hu","lu")) %>%
  ggplot(aes(x = year, y = n, group = archive)) + 
  geom_line(aes(linetype=archive,color = archive), linewidth = 1.2) + 
  theme_minimal() +
  theme(legend.position="bottom",
        legend.title=element_text(size = 12, face = "bold"),
        legend.text=element_text(size = 12, face = "bold"),
        legend.key.width=unit(2,"cm"),
        axis.text=element_text(size=12, face = "bold"),
        axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
#  scale_linetype_manual(values = line_types_dk, labels = line_labels_dk) +
#  scale_color_manual(values = line_colors_dk, labels = line_labels_dk) +
  labs(y = "Number of .dk domains \n", x = "\n Year", color = "Archive", linetype = "Archive")
```


# Figure 3: Top 20 TLDs in the different national archives
Based on statc-distinct-lvl2-per-tld-overall.

## Fig 3 Netarkivet
```{r}
# read data and add column names
dk_lvl2_per_tld <- read.csv("data/nak-all-statc-distinct-lvl2-per-tld-overall.csv", header=FALSE) # It has no headers, so we add the column names
colnames(dk_lvl2_per_tld) = c("TLD","num_domains")

# to see the data to decide how many TLDs to include
head(dk_lvl2_per_tld, 20) # change the number depending on how many you want to see
  
# create top20 and an "Other" category with the rest
percentage_top20_nak <- dk_lvl2_per_tld %>% 
  arrange(desc(num_domains)) %>% # probably not necessary but just to make sure they are properly sorted
  split(c(rep("top", 20), rep("rest", nrow(.) - 20))) %>% # splits into the top 20 and the rest
  (\(s) bind_rows(s$top, data.frame(TLD = "Other", num_domains = sum(s$rest$num_domains)))) %>% # sums num_domains for all from the "other" category
  mutate(percentage = num_domains/sum(num_domains)) # creates a column with the percentages for each TLD and the Other category 

# plot with reorder to order descending based on percentage but with  
percentage_top20_nak %>% 
  ggplot(aes(x=reorder(TLD, -percentage) %>%
               fct_relevel("Other", after = Inf), y=percentage)) + 
  geom_bar(stat="identity", fill="#c9c9c9") +
  theme_minimal() +
  theme(legend.position="none",
        legend.title=element_text(size = 14, face = "bold"),
        legend.text=element_text(size = 14, face = "bold"),
        legend.key.width=unit(2,"cm"), # makes the legend key (the example of the linetype used) longer
        axis.text=element_text(size=14, face = "bold"),
        axis.title=element_text(size=22, face = "bold"),
        axis.title.x=element_blank()) +
  scale_y_continuous(labels = percent) +
  labs(y = "Top 20 TLDs in NAK \n", x = "\n TLD")  

# -percentage means that the order is descending (based on num_domains)
# Inf er for infinite, so here it means that the Other category is placed at the end
# to plot it with Other where it is placed depending on descending num_domains, remove: %>% fct_relevel("Other", after = Inf)

# write_csv(percentage_top20_nak, "results/percentage_top20_nak.csv")
```

## Fig 3 BNF
Based on statc-distinct-lvl2-per-tld-overall.
```{r}
# read data and add column names
bnf_lvl2_per_tld <- read.csv("data/bnf-all-statc-distinct-lvl2-per-tld-overall.csv", header=FALSE) # It has no headers, so we add the column names
colnames(bnf_lvl2_per_tld) = c("TLD","num_domains")

# to see the data to decide how many TLDs to include
head(bnf_lvl2_per_tld, 20) # change the number depending on how many you want to see
  
# create top20 and an "Other" category with the rest
percentage_top20_bnf <- bnf_lvl2_per_tld %>% 
  arrange(desc(num_domains)) %>% # probably not necessary but just to make sure they are properly sorted
  split(c(rep("top", 20), rep("rest", nrow(.) - 20))) %>% # splits into the top 20 and the rest
  (\(s) bind_rows(s$top, data.frame(TLD = "Other", num_domains = sum(s$rest$num_domains)))) %>% # sums num_domains for all from the "other" category
  mutate(percentage = num_domains/sum(num_domains)) # creates a column with the percentages for each TLD and the Other category 

# plot with reorder to order descending based on percentage but with  
percentage_top20_bnf %>% ggplot(aes(x=reorder(TLD, -percentage) %>% fct_relevel("Other", after = Inf), y=percentage)) + 
  geom_bar(stat="identity", fill="#838383") +
  theme_minimal() +
  theme(legend.position="none",
        legend.title=element_text(size = 14, face = "bold"),
        legend.text=element_text(size = 14, face = "bold"),
        legend.key.width=unit(2,"cm"), # makes the legend key (the example of the linetype used) longer
        axis.text=element_text(size=14, face = "bold"),
        axis.title=element_text(size=22, face = "bold"),
        axis.title.x=element_blank()) +
  scale_y_continuous(labels = percent) +
  labs(y = "Top 20 TLDs in BNF \n", x = "\n TLD")  

# write_csv(percentage_top20_bnf, "results/percentage_top20_bnf.csv")
```

## Fig 3 SZL
Based on statc-distinct-lvl2-per-tld-overall.
```{r}
# read data and add column names
szl_lvl2_per_tld <- read.csv("data/szl-all-statc-distinct-lvl2-per-tld-overall.csv", header=FALSE) # It has no headers, so we add the column names
colnames(szl_lvl2_per_tld) = c("TLD","num_domains")

# to see the data to decide how many TLDs to include
head(szl_lvl2_per_tld, 20) # change the number depending on how many you want to see
  
# create top20 and an "Other" category with the rest
percentage_top20_szl <- szl_lvl2_per_tld %>% 
  arrange(desc(num_domains)) %>% # probably not necessary but just to make sure they are properly sorted
  split(c(rep("top", 20), rep("rest", nrow(.) - 20))) %>% # splits into the top 20 and the rest
  (\(s) bind_rows(s$top, data.frame(TLD = "Other", num_domains = sum(s$rest$num_domains)))) %>% # sums num_domains for all from the "other" category
  mutate(percentage = num_domains/sum(num_domains)) # creates a column with the percentages for each TLD and the Other category 

# plot with reorder to order descending based on percentage but with  
percentage_top20_szl %>% ggplot(aes(x=reorder(TLD, -percentage) %>% fct_relevel("Other", after = Inf), y=percentage)) + 
  geom_bar(stat="identity", fill="#3a3a3a") +
  theme_minimal() +
    theme(legend.position="none",
        legend.title=element_text(size = 14, face = "bold"),
        legend.text=element_text(size = 14, face = "bold"),
        legend.key.width=unit(2,"cm"), # makes the legend key (the example of the linetype used) longer
        axis.text=element_text(size=14, face = "bold"),
        axis.title=element_text(size=22, face = "bold"),
        axis.title.x=element_blank()) +
  scale_y_continuous(labels = percent) +
  labs(y = "Top 20 TLDs in SZL \n", x = "\n TLD")  

# write_csv(percentage_top20_szl, "results/percentage_top20_szl.csv")
```

## Fig 3 Luxembourg Web Archive
Based on statc-distinct-lvl2-per-tld-overall.
```{r}
# read data and add column names
lwa_lvl2_per_tld <- read.csv("data/lwa-all-statc-distinct-lvl2-per-tld-overall.csv", header=FALSE) # It has no headers, so we add the column names
colnames(lwa_lvl2_per_tld) = c("TLD","num_domains")

# to see the data to decide how many TLDs to include
head(lwa_lvl2_per_tld, 20) # change the number depending on how many you want to see
  
# create top20 and an "Other" category with the rest
percentage_top20_lwa <- lwa_lvl2_per_tld %>% 
  arrange(desc(num_domains)) %>% # probably not necessary but just to make sure they are properly sorted
  split(c(rep("top", 20), rep("rest", nrow(.) - 20))) %>% # splits into the top 20 and the rest
  (\(s) bind_rows(s$top, data.frame(TLD = "Other", num_domains = sum(s$rest$num_domains)))) %>% # sums num_domains for all from the "other" category
  mutate(percentage = num_domains/sum(num_domains)) # creates a column with the percentages for each TLD and the Other category 

# plot with reorder to order descending based on percentage but with  
percentage_top20_lwa %>% ggplot(aes(x=reorder(TLD, -percentage) %>% fct_relevel("Other", after = Inf), y=percentage)) + 
  geom_bar(stat="identity", fill="#aeaeae") +
  theme_minimal() +
  theme(legend.position="none",
        legend.title=element_text(size = 14, face = "bold"),
        legend.text=element_text(size = 14, face = "bold"),
        legend.key.width=unit(2,"cm"), # makes the legend key (the example of the linetype used) longer
        axis.text=element_text(size=14, face = "bold"),
        axis.title=element_text(size=22, face = "bold"),
        axis.title.x=element_blank()) +
  scale_y_continuous(labels = percent) +
  labs(y = "Top 20 TLDs in LWA \n", x = "\n TLD")  

# write_csv(percentage_top20_lwa, "results/percentage_top20_lwa.csv")
```


# 5. Overlap analysis ###### NOT DONE!!
Based on overlaps_hosts_lu

# Colors & linetypes
"Internet Archive" :  : "dashed"
"Common Crawl" : "#e5e5e5" : "solid"
"Bibliothèque nationale de France" : "#838383" : "twodash"
"Luxembourg Web Archive" : "#aeaeae" : "dotdash"
"Netarkivet" : "#c9c9c9" : "dotted"
"Hungary Web Archive" : "#3a3a3a" : "longdash"

Links for tests with patterns (see also test R file):
https://coolbutuseless.github.io/2020/04/01/introducing-ggpattern-pattern-fills-for-ggplot/
https://coolbutuseless.github.io/package/ggpattern/articles/geom-gallery-geometry.html
https://coolbutuseless.github.io/package/ggpattern/articles/pattern-magick.html - TRY THIS ONE OUT!
https://cran.r-project.org/web/packages/ggpattern/vignettes/patterns-stripes.html
https://stackoverflow.com/questions/74159276/ggpattern-pattern-for-a-specified-value-of-variable

### TEST OVERLAPS PATTERNS - DATA: LWA
# run read data and melt from below first
```{r}
overlaps_hosts_lu_melt %>% 
  ggplot(aes(x=Year, y=n)) +
  geom_col_pattern(
    aes(
      pattern_type = Archive, 
      pattern_fill = Archive
    ),
    pattern       = 'magick',
  #  pattern_key_scale_factor = 0.2,
    fill          = 'white',
    colour        = 'black',
  ) +
#  theme(legend.key.size = unit(4, 'cm')) +
  theme_minimal() +
  theme(legend.position="bottom",
        legend.title=element_text(size = 14, face = "bold"),
        legend.text=element_text(size = 12, face = "bold"), 
        axis.text=element_text(size=12, face = "bold"),
        axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_x_continuous(breaks = overlaps_hosts_lu_melt$year) +
  scale_pattern_type_discrete(choices = pattern_types_lu_subset, labels = pattern_labels_lu_subset) +

  scale_pattern_fill_manual(values = pattern_colors_lu_subset, labels = pattern_labels_lu_subset) +
  guides(fill=guide_legend(nrow=3,byrow=FALSE)) +
  labs(y = "Overlap between archives - .lu domains \n", x = "\n Year", color = "Archive", pattern = "Archive")


# c("verticalsaw","smallfishscales","hexagons","bricks","horisontal","crosshatch","left30")

#choices = c("verticalsaw","smallfishscales","hexagons","bricks","horisontal","crosshatch","left30"



pattern_colors_lu_subset <- c("black","black","black", "black","black","black","black")
pattern_labels_lu_subset <- c("Common Crawl","Internet Archive","LWA","Internet Archive & Common Crawl","LWA & Common Crawl","LWA & Internet Archive","LWA & Internet Archive & Common Crawl")
pattern_types_lu_subset <- c("vertical2","gray95","crosshatch45","gray10","bricks","right30","left30")



  scale_fill_discrete(name = "Income components") +
  scale_pattern_type_discrete(name = "Income components", choices = pat)


#  labs(y = "Number of .dk domains \n", x = "\n Year", color = "Archive")
# labels = c("Common Crawl","Internet Archive","LWA","Internet Archive & Common Crawl","LWA & Common Crawl","LWA & Internet Archive","LWA & Internet Archive & Common Crawl")

TJEK OGSÅ DEN HER: https://community.rstudio.com/t/barplot-with-different-pattern/139915 
og evt. https://stackoverflow.com/questions/72714373/ggplot-with-patterns-and-colors-legend 
  
```


## LWA
```{r}
# read data
overlaps_hosts_lu <- read_csv2("data/overlaps_hosts_lu.csv")

# create long format for ggplot
overlaps_hosts_lu_melt <- melt(overlaps_hosts_lu, 
                        id.var="Year",
                        measure.vars = colnames(overlaps_hosts_lu)[! colnames(overlaps_hosts_lu) %in% c("Year")],
                        variable.name = "Archive", 
                        value.name = "n")
# plot
overlaps_hosts_lu_melt %>% 
  ggplot(aes(x=Year, y=n, fill=Archive)) +
  geom_bar(stat="identity") +
  theme_minimal() +
  theme(legend.position="bottom",
        legend.title=element_text(size = 14, face = "bold"),
        legend.text=element_text(size = 12, face = "bold"), 
        axis.text=element_text(size=12, face = "bold"),
        axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_x_continuous(breaks = overlaps_hosts_lu_melt$year) +
#  scale_fill_manual(values = c("#e5e5e5","#000000","#aeaeae","aquamarine","cadetblue2","cornflowerblue","cyan"), labels = c("Common Crawl","Internet Archive","LWA","Internet Archive & Common Crawl","LWA & Common Crawl","LWA & Internet Archive","LWA & Internet Archive & Common Crawl")) +
  scale_pattern_manual(values=c("stripe","stripe","stripe","stripe","crosshatch","weave","wave")) +
  guides(fill=guide_legend(nrow=3,byrow=FALSE)) +
  labs(y = "Number of .dk domains \n", x = "\n Year", color = "Archive")
```


## BNF
Based on overlaps_hosts_bnf
```{r}
# read data
overlaps_hosts_bnf <- read_csv2("data_overlaps/overlaps_hosts_bnf.csv")

# create long format for ggplot
overlaps_hosts_bnf_melt <- melt(overlaps_hosts_bnf, 
                        id.var="Year",
                        measure.vars = colnames(overlaps_hosts_bnf)[! colnames(overlaps_hosts_bnf) %in% c("Year")],
                        variable.name = "Archive", 
                        value.name = "n")
# plot
overlaps_hosts_bnf_melt %>% ggplot(aes(x=Year, y=n, fill=Archive)) +
  geom_bar(stat="identity") +
  theme_minimal() +
  theme(legend.title=element_text(size = 14, face = "bold")) +
  theme(legend.text=element_text(size = 12, face = "bold")) + 
  theme(axis.text=element_text(size=12, face = "bold"),axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_x_continuous(breaks = clean_domains_per_year$year) +
  scale_fill_manual(values = c("orange2","navyblue","gold","aquamarine","cadetblue2","cornflowerblue","cyan"),
  labels = c("Common Crawl","Internet Archive","BNF","Internet Archive & Common Crawl","BNF & Common Crawl","BNF & Internet Archive","BNF & Internet Archive & Common Crawl")) + 
  labs(y = "Number of .dk domains \n", x = "\n Year", color = "Archive")
```

## SZL - WRONG DATA! NEED NEW DATA!!!
Based on overlaps_hosts_szl
```{r}
# read data
overlaps_hosts_szl <- read_csv2("data/overlaps_hosts_hu.csv")

# create long format for ggplot
overlaps_hosts_szl_melt <- melt(overlaps_hosts_szl, 
                        id.var="Year",
                        measure.vars = colnames(overlaps_hosts_szl)[! colnames(overlaps_hosts_szl) %in% c("Year")],
                        variable.name = "Archive", 
                        value.name = "n")
# plot
overlaps_hosts_szl_melt %>% ggplot(aes(x=Year, y=n, fill=Archive)) +
  geom_bar(stat="identity") +
  theme_minimal() +
  theme(legend.title=element_text(size = 14, face = "bold")) +
  theme(legend.text=element_text(size = 12, face = "bold")) + 
  theme(axis.text=element_text(size=12, face = "bold"),axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_x_continuous(breaks = overlaps_hosts_szl$year) +
  scale_fill_manual(values = c("#aeaeae","#000000","#e5e5e5","#838383","#c9c9c9","#3a3a3a", "#121212")) +
#  scale_fill_manual(values = c("orange2","navyblue","darkorchid3","aquamarine","cadetblue2","cornflowerblue","cyan"), labels = c("Common Crawl","Internet Archive","SZL","Internet Archive & Common Crawl","SZL & Common Crawl","SZL & Internet Archive","SZL & Internet Archive & Common Crawl")) + 
  labs(y = "Number of .dk domains \n", x = "\n Year", color = "Archive")
```

## .dk - WRONG DATA! NEED NEW DATA!!!
```{r}
# read data
overlaps_hosts_dk <- read_csv2("data/overlaps_hosts_dk_2.csv")

# create long format for ggplot
overlaps_hosts_dk_melt <- melt(overlaps_hosts_dk, 
                        id.var="Year",
                        measure.vars = colnames(overlaps_hosts_dk)[! colnames(overlaps_hosts_dk) %in% c("Year")],
                        variable.name = "Archive", 
                        value.name = "n")
# plot
overlaps_hosts_dk_melt %>% ggplot(aes(x=Year, y=n, fill=Archive)) +
  geom_bar(stat="identity") +
  theme_minimal() +
  theme(legend.title=element_text(size = 16, face = "bold")) +
  theme(legend.text=element_text(size = 14, face = "bold")) + 
  theme(axis.text=element_text(size=14, face = "bold"),axis.title=element_text(size=16, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_x_continuous(breaks = clean_domains_per_year$year) +
  scale_fill_manual(values = c("cadetblue2","cornflowerblue","aquamarine","blue","cyan","dodgerblue","navyblue"),labels = c("Internet Archive","Common Crawl","Netarkivet","Internet Archive & Common Crawl","Netarkivet & Common Crawl","Netarkivet & Internet Archive","Netarkivet, Internet Archive & Common Crawl")) + 
  labs(y = "Number of .dk domains \n", x = "\n Year", color = "Archive")
```

# 6. Distinct TLDs in the national archives (not BNF)
Based on distinct-tld-overall and distinct-tld-per-year.csv (the ones with all)
```{r}
# distinct tld overall
# read files and add column names
distinct_tld_overall <- read_data_files("data", "*distinct-tld-overall.csv", c("n")) %>% 
  separate(collection, c("archive", "country"), remove=TRUE) %>%
  select(-c("country")) %>%
  arrange(desc(n))

# write to csv (optional)
# write_csv(distinct_tld_overall, "results/distinct_tld_overall.csv")

# distinct tld per year
# read files and add column names + column with archive name for
szl_tld_year <- read.csv("data/szl-all-statb-distinct-tld-per-year.csv", header = FALSE) 
colnames(szl_tld_year) <- c("year","n_tlds") # name columns
szl_tld_per_year <- szl_tld_year %>%
  mutate(archive="szl") # add column with archive name, new name so the former can be used for printing the combined df below, too

lwa_tld_year <- read.csv("data/lwa-all-statb-distinct-tld-per-year.csv", header = FALSE) 
colnames(lwa_tld_year) <- c("year","n_tlds") # name columns
lwa_tld_per_year <- lwa_tld_year %>%
  mutate(archive="lwa") # add column with archive name

nak_tld_year <- read.csv("data/nak-all-statb-distinct-tld-per-year.csv", header = FALSE) 
colnames(nak_tld_year) <- c("year","n_tlds") # name columns
nak_tld_per_year <- nak_tld_year %>%
  mutate(archive="nak") # add column with archive name

distinct_tlds_per_year <- rbind(szl_tld_per_year,lwa_tld_per_year,nak_tld_per_year)

# sort colors and labels in the right order
line_colors_tlds_per_year <- c("#c9c9c9","#aeaeae","#3a3a3a")
line_labels_tlds_per_year <- c("Netarkivet", "Luxembourg Web Archive", "Hungary Web Archive")
line_types_tlds_per_year <- c("dotted","dotdash","longdash")

distinct_tlds_per_year %>%
  mutate(archive = fct_relevel(archive,"nak","lwa","szl")) %>%
  ggplot(aes(x=year, y=n_tlds, group=archive)) + 
  geom_line(aes(linetype=archive,color = archive), linewidth = 1.2) +
  theme_minimal() +
  theme(legend.position="bottom",
        legend.title=element_text(size = 12, face = "bold"),
        legend.text=element_text(size = 12, face = "bold"),
        legend.key.width=unit(2,"cm"),
        axis.text=element_text(size=12, face = "bold"),
        axis.title=element_text(size=12, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  scale_x_continuous(breaks = distinct_tlds_per_year$year) +
  scale_linetype_manual(values = line_types_tlds_per_year, labels = line_labels_tlds_per_year) +
  scale_color_manual(values = line_colors_tlds_per_year, labels = line_labels_tlds_per_year) +
  labs(y = "Number of TLDs \n", x = "\n Year", color = "Archive", linetype = "Archive")

# write to csv (optional)
# for more appropriate format for csv, rename column with archive name

nak_tld_year_write <- nak_tld_year
colnames(nak_tld_year_write) <- c("year","nak") # name columns

lwa_tld_year_write <- lwa_tld_year
colnames(lwa_tld_year_write) <- c("year","lwa") # name columns

szl_tld_year_write <- szl_tld_year
colnames(szl_tld_year_write) <- c("year","szl") # name columns

distinct_tlds_per_year_df_prelim <- merge(nak_tld_year_write,lwa_tld_year_write,by = "year", all=TRUE)
distinct_tlds_per_year_df <- merge(distinct_tlds_per_year_df_prelim,szl_tld_year_write,by = "year", all=TRUE)

# write_csv(distinct_tlds_per_year_df, "results/distinct_tlds_per_year_df.csv")
```


EXTRA

# OLD VERSION OF 2 FACETS

# 2. Number of distinct domains in all archives across years shown as facets
Based on stata-distinct-domains-per-year
###TO DO: find a way to sort the facets so they appear in the correct order 
```{r}
# read files and remove years that are errors
clean_domains_per_year <- read_data_files("data","*domains-per-year.csv", c("year", "count")) %>%  
  filter(year > 1992)  %>%
  filter(year < 2022) %>% 
  separate(collection, c("archive", "country"), remove=FALSE)

# to see how many years are represented for each country in each archive 
# clean_domains_per_year %>% count(archive, country)

# collections as facets, full version
clean_domains_per_year %>% 
  ggplot(aes(x=year, y=count/1000000)) +
  geom_bar(stat="identity") +
  facet_wrap(~collection) +
  theme_minimal() +
  theme(legend.title=element_text(size = 14, face = "bold")) +
  theme(legend.text=element_text(size = 12, face = "bold")) + 
  theme(axis.text=element_text(size=12, face = "bold"),axis.title=element_text(size=12, face = "bold")) +
  theme(strip.text.x = element_text(size = 11, face = "bold"), strip.text.y = element_text(size = 11, face = "bold")) +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  labs(y = "Number of domains in millions \n", x = "")

# collections as facets, only national archives
clean_domains_per_year  %>%
  filter(archive %in% c("bnf", "lwa", "szl")) %>% ### remember to include nak!
  ggplot(aes(x=year, y=count/1000000)) +
  geom_bar(stat="identity") +
  facet_wrap(~collection,ncol=2, labeller=labeller(collection = 
    c("bnf-all" = "BNF, all TLDs",
      "bnf-fr" = "BNF, only .fr",
      "lwa-all" = "LWA, all TLDs",
      "lwa-lu" = "LWA, only .lu",
      "szl-all" = "SZL, all TLDs",
      "szl-hu" = "SZL, only .hu"))) +
  theme_minimal() +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  labs(y = "Number of domains in millions \n", x = "")
# ncol sets the number of columns, add scales = "free_y" to facet_wrap for diff values on y-axes

# collections as facets, only ccTLDs
clean_domains_per_year %>%
  filter(country!="all") %>%
  filter(country!="dk") %>% # as long as we don't have the Danish data, delete filter when we have the data
  mutate(across(collection, factor, levels=c("bnf-fr","lwa-lu","szl-hu", "ia-fr", "ia-lu", "ia-hu","cc-fr", "cc-lu", "cc-hu"))) %>%
  ggplot(aes(x=year, y=count/1000000)) +
  geom_bar(stat="identity") +
  facet_wrap(~collection,ncol=3) + # add scales = "free_y" for different scales on y-axes
  theme_minimal() +
  scale_y_continuous(labels = function(x) format(x, big.mark = ".", decimal.mark = ",", scientific = F)) +
  labs(y = "Number of domains in millions \n", x = "")
# TO DO: add labels
  
# for only one condition: filter(archive=="bnf") for only bnf OR filter(archive!="bnf") for all archives except bnf (!= means not equal to)
```


###TEST COLOUR SCHEME
```{r}
"Internet Archive" : "#000000" : "dashed"
"Common Crawl" : "#e5e5e5" : "solid" 
"Bibliothèque nationale de France" : "#838383" : "twodash"
"Luxembourg Web Archive" : "#aeaeae" : "dotdash"
"Netarkivet" : "#c9c9c9" : "dotted"
"Hungary Web Archive" : "#3a3a3a" : "longdash"
```

# Knit to create pdf report
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
